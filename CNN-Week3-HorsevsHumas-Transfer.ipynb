{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 7 - Question.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "lbFmQdsZs5eW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        },
        "outputId": "fce1e5ae-279e-4bcc-e18a-38ab355ddec7"
      },
      "source": [
        "# Import all the necessary files!\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1xJZ5glPPCRz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5ba5a2b8-91c0-4be6-e266-d7f7c121bdd8"
      },
      "source": [
        "# Download the inception v3 weights\n",
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n",
        "    -O /tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
        "\n",
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
        "\n",
        "# Create an instance of the inception model from the local pre-trained weights\n",
        "local_weights_file = '/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "\n",
        "pre_trained_model = InceptionV3(input_shape = (150, 150, 3), \n",
        "                                include_top = False, \n",
        "                                weights = None)\n",
        "\n",
        "pre_trained_model.load_weights(local_weights_file)\n",
        "\n",
        "# Make all the layers in the pre-trained model non-trainable\n",
        "for layer in pre_trained_model.layers:\n",
        "  layer.trainable = False\n",
        "  \n",
        "# Print the model summary\n",
        "pre_trained_model.summary()\n",
        "\n",
        "# Expected Output is extremely large, but should end with:\n",
        "\n",
        "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
        "#                                                                 activation_276[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
        "#                                                                 activation_280[0][0]             \n",
        "#__________________________________________________________________________________________________\n",
        "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
        "#__________________________________________________________________________________________________\n",
        "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
        "#                                                                 mixed9_1[0][0]                   \n",
        "#                                                                 concatenate_5[0][0]              \n",
        "#                                                                 activation_281[0][0]             \n",
        "#==================================================================================================\n",
        "#Total params: 21,802,784\n",
        "#Trainable params: 0\n",
        "#Non-trainable params: 21,802,784"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-11 17:09:11--  https://storage.googleapis.com/mledu-datasets/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.24.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.24.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 87910968 (84M) [application/x-hdf]\n",
            "Saving to: ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’\n",
            "\n",
            "/tmp/inception_v3_w 100%[===================>]  83.84M  38.5MB/s    in 2.2s    \n",
            "\n",
            "2020-03-11 17:09:14 (38.5 MB/s) - ‘/tmp/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5’ saved [87910968/87910968]\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 7, 7, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 7, 7, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 7, 7, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 7, 7, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 7, 7, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 7, 7, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 7, 7, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 7, 7, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 7, 7, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 7, 7, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 3, 3, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 3, 3, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 3, 3, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 3, 3, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 3, 3, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 3, 3, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 3, 3, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 3, 3, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 3, 3, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 3, 3, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 3, 3, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 3, 3, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 3, 3, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 3, 3, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 3, 3, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 3, 3, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 3, 3, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 3, 3, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 3, 3, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 3, 3, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 3, 3, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 3, 3, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 3, 3, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 3, 3, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 3, 3, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 3, 3, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 3, 3, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 3, 3, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 3, 3, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 3, 3, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 3, 3, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 3, 3, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 3, 3, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 3, 3, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 3, 3, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 3, 3, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 3, 3, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 3, 3, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 3, 3, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 3, 3, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 3, 3, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 3, 3, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 3, 3, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 3, 3, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 3, 3, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 3, 3, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 3, 3, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 3, 3, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 3, 3, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 3, 3, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 21,802,784\n",
            "Trainable params: 0\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CFsUlwdfs_wg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "63817635-a583-4ece-ce01-930370c5aec5"
      },
      "source": [
        "last_layer = pre_trained_model.get_layer('mixed7')\n",
        "print('last layer output shape: ', last_layer.output_shape)\n",
        "last_output = last_layer.output\n",
        "\n",
        "# Expected Output:\n",
        "# ('last layer output shape: ', (None, 7, 7, 768))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "last layer output shape:  (None, 7, 7, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bsWZWp5oMq9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('acc')>0.999):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BMXb913pbvFg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc69e786-b92a-4732-fdc4-493e2e745346"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(last_output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
        "\n",
        "model = Model( pre_trained_model.input, x) \n",
        "\n",
        "model.compile(optimizer = RMSprop(lr=0.0001), \n",
        "              loss = 'binary_crossentropy', \n",
        "              metrics = ['acc'])\n",
        "\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# Expected output will be large. Last few lines should be:\n",
        "\n",
        "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
        "#                                                                  activation_251[0][0]             \n",
        "#                                                                  activation_256[0][0]             \n",
        "#                                                                  activation_257[0][0]             \n",
        "# __________________________________________________________________________________________________\n",
        "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
        "# __________________________________________________________________________________________________\n",
        "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
        "# __________________________________________________________________________________________________\n",
        "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
        "# ==================================================================================================\n",
        "# Total params: 47,512,481\n",
        "# Trainable params: 38,537,217\n",
        "# Non-trainable params: 8,975,264\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 74, 74, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 74, 74, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 74, 74, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 72, 72, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 72, 72, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 72, 72, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 72, 72, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 72, 72, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 72, 72, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 35, 35, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 35, 35, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 35, 35, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 35, 35, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 33, 33, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 33, 33, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 33, 33, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 16, 16, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 16, 16, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 16, 16, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 16, 16, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 16, 16, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 16, 16, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 16, 16, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 16, 16, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 16, 16, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 16, 16, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 16, 16, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 16, 16, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 16, 16, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 16, 16, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 16, 16, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 16, 16, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 16, 16, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 16, 16, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 16, 16, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 16, 16, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 16, 16, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 16, 16, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 7, 7, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 7, 7, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 7, 7, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 7, 7, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 7, 7, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 7, 7, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 7, 7, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 7, 7, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 7, 7, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 7, 7, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 7, 7, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 7, 7, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 7, 7, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 7, 7, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 7, 7, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 7, 7, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 7, 7, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 7, 7, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 7, 7, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 7, 7, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 7, 7, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 7, 7, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 7, 7, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 7, 7, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 7, 7, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 7, 7, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 7, 7, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 7, 7, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 7, 7, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 7, 7, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 7, 7, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 7, 7, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 7, 7, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 7, 7, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 7, 7, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 7, 7, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 7, 7, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 7, 7, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 7, 7, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 7, 7, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 7, 7, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 7, 7, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 7, 7, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 7, 7, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 7, 7, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 7, 7, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 7, 7, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 7, 7, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 7, 7, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 7, 7, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 7, 7, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 7, 7, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 7, 7, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 7, 7, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 7, 7, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 7, 7, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 7, 7, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 7, 7, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 7, 7, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 7, 7, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 7, 7, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 7, 7, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 7, 7, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 7, 7, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 7, 7, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 7, 7, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 7, 7, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 7, 7, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 7, 7, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 7, 7, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 7, 7, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 7, 7, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 7, 7, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 7, 7, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 7, 7, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 7, 7, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 7, 7, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 7, 7, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 7, 7, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 7, 7, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 7, 7, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 7, 7, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 7, 7, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 7, 7, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 7, 7, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 7, 7, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 7, 7, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 7, 7, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 7, 7, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 7, 7, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 7, 7, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 7, 7, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 7, 7, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 7, 7, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 7, 7, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 7, 7, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 7, 7, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 7, 7, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 7, 7, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 7, 7, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 7, 7, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 7, 7, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 7, 7, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 7, 7, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 7, 7, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 7, 7, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 7, 7, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 7, 7, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 7, 7, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 47,512,481\n",
            "Trainable params: 38,537,217\n",
            "Non-trainable params: 8,975,264\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrnL_IQ8knWA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "832b228b-2ccd-4820-cf67-98d5e1d16865"
      },
      "source": [
        "# Get the Horse or Human dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip -O /tmp/horse-or-human.zip\n",
        "\n",
        "# Get the Horse or Human Validation dataset\n",
        "!wget --no-check-certificate https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip -O /tmp/validation-horse-or-human.zip \n",
        "  \n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '//tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/training')\n",
        "zip_ref.close()\n",
        "\n",
        "local_zip = '//tmp/validation-horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/validation')\n",
        "zip_ref.close()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-03-11 17:12:33--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.200.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.200.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M  30.1MB/s    in 4.7s    \n",
            "\n",
            "2020-03-11 17:12:39 (30.1 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n",
            "--2020-03-11 17:12:40--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/validation-horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.253.118.128, 2404:6800:4003:c03::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.253.118.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11480187 (11M) [application/zip]\n",
            "Saving to: ‘/tmp/validation-horse-or-human.zip’\n",
            "\n",
            "/tmp/validation-hor 100%[===================>]  10.95M  19.8MB/s    in 0.6s    \n",
            "\n",
            "2020-03-11 17:12:41 (19.8 MB/s) - ‘/tmp/validation-horse-or-human.zip’ saved [11480187/11480187]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9okX7_ovskI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2f121d5b-7efa-4601-ab0f-79f786abf663"
      },
      "source": [
        "# Directory with our training horse pictures\n",
        "train_horse_dir = os.path.join('/tmp/training/horses')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "train_human_dir = os.path.join('/tmp/training/humans')\n",
        "\n",
        "# Directory with our training horse pictures\n",
        "validation_horse_dir = os.path.join('/tmp/validation/horses')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "validation_human_dir = os.path.join('/tmp/validation/humans')\n",
        "\n",
        "train_horses_fnames = os.listdir(train_horse_dir)\n",
        "train_humans_fnames = os.listdir(train_human_dir)\n",
        "validation_horses_fnames = os.listdir(validation_horse_dir)\n",
        "validation_humans_fnames = os.listdir(validation_human_dir)\n",
        "\n",
        "print(len(train_horses_fnames))\n",
        "print(len(train_humans_fnames))\n",
        "print(len(validation_horses_fnames))\n",
        "print(len(validation_humans_fnames))\n",
        "\n",
        "# Expected Output:\n",
        "# 500\n",
        "# 527\n",
        "# 128\n",
        "# 128"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "527\n",
            "128\n",
            "128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "O4s8HckqGlnb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3ddf3c10-5768-48d1-f7e0-3d29d03c94b1"
      },
      "source": [
        "# Define our example directories and files\n",
        "train_dir = '/tmp/training'\n",
        "validation_dir = '/tmp/validation'\n",
        "\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(\n",
        "      rescale=1./255,\n",
        "      rotation_range=40,\n",
        "      width_shift_range=0.2,\n",
        "      height_shift_range=0.2,\n",
        "      shear_range=0.2,\n",
        "      zoom_range=0.2,\n",
        "      horizontal_flip=True,\n",
        "      fill_mode='nearest')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/training/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=128,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "# Flow training images in batches of 128 using train_datagen generator\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        '/tmp/validation/',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=32,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "\n",
        "# Expected Output:\n",
        "# Found 1027 images belonging to 2 classes.\n",
        "# Found 256 images belonging to 2 classes."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n",
            "Found 256 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Blhq2MAUeyGA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5b838c92-5243-4224-d151-15157e583b87"
      },
      "source": [
        "# Run this and see how many epochs it should take before the callback\n",
        "# fires, and stops training at 99.9% accuracy\n",
        "# (It should take less than 100 epochs)\n",
        "\n",
        "callbacks = myCallback()\n",
        "history = model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=8,  \n",
        "      epochs=100,\n",
        "      verbose=1,\n",
        "      validation_data = validation_generator,\n",
        "      validation_steps=8, callbacks=[callbacks])\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "7/8 [=========================>....] - ETA: 1s - loss: 0.7883 - acc: 0.6900Epoch 1/100\n",
            "8/8 [==============================] - 2s 244ms/step - loss: 0.1141 - acc: 0.9766\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.7289 - acc: 0.7141 - val_loss: 0.1141 - val_acc: 0.9766\n",
            "Epoch 2/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1291 - acc: 0.9792Epoch 1/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.0354 - acc: 0.9805\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.1703 - acc: 0.9499 - val_loss: 0.0354 - val_acc: 0.9805\n",
            "Epoch 3/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.2207 - acc: 0.9235Epoch 1/100\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 0.0079 - acc: 1.0000\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.2031 - acc: 0.9299 - val_loss: 0.0079 - val_acc: 1.0000\n",
            "Epoch 4/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0638 - acc: 0.9896Epoch 1/100\n",
            "8/8 [==============================] - 1s 151ms/step - loss: 0.0270 - acc: 0.9922\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0756 - acc: 0.9800 - val_loss: 0.0270 - val_acc: 0.9922\n",
            "Epoch 5/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.1403 - acc: 0.9650Epoch 1/100\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 0.0163 - acc: 0.9961\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.1226 - acc: 0.9677 - val_loss: 0.0163 - val_acc: 0.9961\n",
            "Epoch 6/100\n",
            "7/8 [=========================>....] - ETA: 1s - loss: 0.0383 - acc: 0.9888Epoch 1/100\n",
            "8/8 [==============================] - 1s 147ms/step - loss: 0.1663 - acc: 0.9375\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0384 - acc: 0.9889 - val_loss: 0.1663 - val_acc: 0.9375\n",
            "Epoch 7/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0462 - acc: 0.9870Epoch 1/100\n",
            "8/8 [==============================] - 1s 144ms/step - loss: 0.0646 - acc: 0.9766\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0552 - acc: 0.9833 - val_loss: 0.0646 - val_acc: 0.9766\n",
            "Epoch 8/100\n",
            "7/8 [=========================>....] - ETA: 1s - loss: 0.1245 - acc: 0.9475Epoch 1/100\n",
            "8/8 [==============================] - 1s 143ms/step - loss: 0.0103 - acc: 0.9961\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.1111 - acc: 0.9541 - val_loss: 0.0103 - val_acc: 0.9961\n",
            "Epoch 9/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0259 - acc: 0.9909Epoch 1/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 6.9206e-04 - acc: 1.0000\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0284 - acc: 0.9911 - val_loss: 6.9206e-04 - val_acc: 1.0000\n",
            "Epoch 10/100\n",
            "7/8 [=========================>....] - ETA: 1s - loss: 0.0230 - acc: 0.9944Epoch 1/100\n",
            "8/8 [==============================] - 1s 99ms/step - loss: 0.0628 - acc: 0.9727\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0313 - acc: 0.9902 - val_loss: 0.0628 - val_acc: 0.9727\n",
            "Epoch 11/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.4126 - acc: 0.9814Epoch 1/100\n",
            "8/8 [==============================] - 1s 149ms/step - loss: 4.6829e-04 - acc: 1.0000\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.3274 - acc: 0.9832 - val_loss: 4.6829e-04 - val_acc: 1.0000\n",
            "Epoch 12/100\n",
            "7/8 [=========================>....] - ETA: 1s - loss: 0.0175 - acc: 0.9955Epoch 1/100\n",
            "8/8 [==============================] - 1s 144ms/step - loss: 2.4655e-04 - acc: 1.0000\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0156 - acc: 0.9956 - val_loss: 2.4655e-04 - val_acc: 1.0000\n",
            "Epoch 13/100\n",
            "6/8 [=====================>........] - ETA: 2s - loss: 0.0283 - acc: 0.9896Epoch 1/100\n",
            "8/8 [==============================] - 1s 140ms/step - loss: 4.2601e-04 - acc: 1.0000\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0270 - acc: 0.9900 - val_loss: 4.2601e-04 - val_acc: 1.0000\n",
            "Epoch 14/100\n",
            "7/8 [=========================>....] - ETA: 0s - loss: 0.0686 - acc: 0.9805Epoch 1/100\n",
            "8/8 [==============================] - 1s 141ms/step - loss: 2.1101e-04 - acc: 1.0000\n",
            "8/8 [==============================] - 9s 1s/step - loss: 0.0639 - acc: 0.9822 - val_loss: 2.1101e-04 - val_acc: 1.0000\n",
            "Epoch 15/100\n",
            "7/8 [=========================>....] - ETA: 1s - loss: 0.0089 - acc: 0.9989Epoch 1/100\n",
            "8/8 [==============================] - 1s 146ms/step - loss: 1.1872e-04 - acc: 1.0000\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "8/8 [==============================] - 10s 1s/step - loss: 0.0083 - acc: 0.9990 - val_loss: 1.1872e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2Fp6Se9rKuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "03d96ebf-ec2c-476e-cec4-754035b527f0"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "acc = history.history['acc']\n",
        "val_acc = history.history['val_acc']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend(loc=0)\n",
        "plt.figure()\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhLn/B8iRMmw+haXqAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}